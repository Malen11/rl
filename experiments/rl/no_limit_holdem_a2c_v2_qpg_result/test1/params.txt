#env nums
env_num = 1

# Set the iterations numbers and how frequently we evaluate/save plot
evaluate_every = 25000 // env_num
evaluate_num = 10000
episode_num = 1000000 // env_num

# Train the agent every X steps
train_every = 2048


action_num=env.action_num,
state_shape=env.state_shape,

discount_factor=0.9,

critic_mlp_layers=[4,512],
critic_activation_func='tanh', 
critic_kernel_initializer='glorot_uniform',
critic_learning_rate=0.0001,
critic_bacth_size=128,

actor_mlp_layers=[4,512],
actor_activation_func='tanh', 
actor_kernel_initializer='glorot_uniform', 
actor_learning_rate=0.0001,
actor_bacth_size=512,

entropy_coef=1,
entropy_decoy=math.pow(0.01/1, 1.0/(episode_num//train_every)),
#max_entropy_part=1.2,

max_grad_norm = 1,